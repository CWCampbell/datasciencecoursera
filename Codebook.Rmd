---
title: "Final Project Codebook"
author: "Caren Weiner Campbell"
date: "February 27, 2016"
output: 
  html_document: 
    keep_md: yes
---

---------

**Data Description:** Recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.  

**Number of Instances:** 10299  

**Number of Attributes:** 561  

**Date Provided:** 2012-12-10  

**Data Source:** Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2)  

*1 - Smartlab - Non-Linear Complex Systems Laboratory  
DITEN - Università degli Studi di Genova, Genoa (I-16145), Italy.  
2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living  
Universitat Politècnica de Catalunya (BarcelonaTech). Vilanova i la Geltrú (08800), Spain     activityrecognition "@" smartlab.ws*


**Dataset Information:**  
Experiments were carried out by 30 volunteers between the ages of 19 and 48. Each person performed six activities (walking, walking upstairs, walking downstairs, sitting, standing, laying) wearing a smartphone (Samsung Galaxy S II) on the waist.   

Using the phone's embedded accelerometer and gyroscope, the researchers captured triaxial linear acceleration and triaxial angular velocity at a constant rate of 50Hz. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). 

The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low-frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. 

From each window, a vector of features was obtained by calculating variables from the time and frequency domain.

The full dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.

**Files in Dataset:**  

+ features_info.txt: Information about the variables used on the feature vector  
+ features.txt: List of all features  
+ activity_labels.txt: Links the class labels with their activity names  
+ train/X_train.txt: Training set  
+ train/y_train.txt: Training labels  
+ test/X_test.txt: Test set  
+ test/y_test.txt: Test labels  

The following files are available for the train and test data. Their descriptions are equivalent. 
        
+ subject_train.txt: Each row identifies the subject who performed the activity for each window sample. The range of this variable is from 1 to 30. 

+ total_acc_x_train.txt: The acceleration signal from the smartphone accelerometer X axis in standard gravity units (*g*). The same description applies for the total_acc_y_train.txt and total_acc_z_train.txt files for the Y and Z axes. 

+ body_acc_x_train.txt: The body acceleration signal obtained by subtracting the gravity from the total acceleration. 

+ body_gyro_x_train.txt: The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second. 

**Variables for Each Record in the Dataset:**  

+ Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration  
+ Triaxial angular velocity from the gyroscope  
+ A 561-feature vector with time and frequency domain variables  
+ Its activity label  
+ An identifier of the subject who carried out the experiment  

**Notes on Units and Scale:**  

+ Features are normalized and bounded within [-1,1].  
+ The units used for the accelerations (total and body) are *g*'s (gravity of earth = 9.80665 m/sec^2^).  
+ The gyroscope units are radians/second.   

**Opening the Tidy Dataset:**

This function will read the file from the working directory and then open it.

<pre>tidy_dataset2  <- read.table("./tidy_dataset.txt", header=TRUE)  
tidy_dataset2
</pre>
